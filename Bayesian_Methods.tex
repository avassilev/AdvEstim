% !TeX spellcheck = en_GB
\documentclass[10pt]{beamer}
\usetheme{CambridgeUS}
%\usetheme{Boadilla}
\definecolor{myred}{RGB}{163,0,0}
%\usecolortheme[named=blue]{structure}
\usecolortheme{dove}
\usefonttheme[]{professionalfonts}
\usepackage[english]{babel}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{xcolor}
\usepackage{bm}
\usepackage{gensymb}
\usepackage{verbatim} 
\usepackage{paratype}
\usepackage{mathpazo}
\usepackage{listings}
\lstset{language=R}

\usepackage{tikz}
\usetikzlibrary{matrix}

\DeclareMathOperator*{\interior}{int}

% Number theorem environments
\setbeamertemplate{theorem}[ams style]
\setbeamertemplate{theorems}[numbered]

% Reset theorem-like environments so that each is numbered separately
\usepackage{etoolbox}
\undef{\definition}
\theoremstyle{definition}
\newtheorem{definition}{\translate{Definition}}
\newtheorem{Fact}{\translate{Fact}}

% Change colours for theorem-like environments
\definecolor{mygreen1}{RGB}{0,96,0}
\definecolor{mygreen2}{RGB}{229,239,229}
\setbeamercolor{block title}{fg=white,bg=mygreen1}
\setbeamercolor{block body}{fg=black,bg=mygreen2}



\alt<presentation>
{\lstset{%
  basicstyle=\footnotesize\ttfamily,
  commentstyle=\slshape\color{green!50!black},
  frame = single,  
  keywordstyle=\bfseries\color{blue!50!black},
  identifierstyle=\color{blue},
  stringstyle=\color{orange},
  %escapechar=\#,
  showstringspaces = false,
  showtabs = false,
  tabsize = 2,
  emphstyle=\color{red}}
}
{
  \lstset{%
    basicstyle=\ttfamily,
    keywordstyle=\bfseries,
    commentstyle=\itshape,
    escapechar=\#,
    showtabs = false,
	tabsize = 2,
    emphstyle=\bfseries\color{red}
  }
} 

\title{R404: Advanced Estimation Techniques}
\subtitle{Topic: Bayesian Methods in Econometrics}
\author{Andrey Vassilev}

\date{2016/2017} 
    
\AtBeginSection{\frame{\usebeamerfont{section title}\centering\insertsection}}

\begin{document}
\maketitle



\begin{frame}[fragile]
\frametitle{Lecture Contents}
\tableofcontents
\end{frame}

\begin{section}{Review: the philosophy of the Bayesian approach}\label{sec:BayesPhil}

\begin{frame}
\frametitle{A classical estimation example}
\begin{itemize}\itemsep1em
\item Consider a sample of iid observations $x_1,\ldots,x_n$ coming from a random variable $\xi \sim N(\mu,\sigma^2)$.
\item We are interested in obtaining an estimate of the mean.
\item A standard approach would be to use the method of maximum likelihood (MML).
\item We construct the likelihood function (recall the convention to write it as if conditioning on the data):
\begin{equation}
\label{eq:NormLik}
\begin{split}
L(\mu,\sigma^2|x_1,\ldots,x_n)= & \prod_{i=1}^{n}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}\frac{(x_i-\mu)^2}{\sigma^2}}\\
= & \left(
\frac{1}{2\pi\sigma^2}
\right)^{n/2}e^{-\frac{1}{2}\sum_{i=1}^{n}\frac{(x_i-\mu)^2}{\sigma^2}}.
\end{split}
\end{equation}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{A classical estimation example}
\begin{itemize}\itemsep1em
\item According to the MML, we maximize $ L $ w.r.t. $ \mu $.
\item It is well-known (or, if your recollections are hazy, you can derive it) that the solution is given by the estimator $\hat{\mu}=\sum_{i=1}^{n}x_i/n$, i.e. the sample mean.
\item By definition, the statistic $\hat{\mu}$ is a random variable.
\item Consequently, if we keep repeating the experiment and regenerating the $ n $ observations, we'll obtain new samples $\tilde{x}_1,\ldots,\tilde{x}_n$,  $\tilde{\tilde{x}}_1,\ldots,\tilde{\tilde{x}}_n$ etc. and therefore new values of $\hat{\mu}$.
\item For each of those samples the corresponding value $\hat{\mu}$ will be our estimate of the unknown parameter $ \mu $.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{A classical estimation example}
\begin{itemize}\itemsep1em
\item When we speak of the statistical properties of $\hat{\mu}$ like unbiasedness or consistency, we are implicitly referring to an ability to repeat the experiment many times or to extend the sample size $ n $ within an experiment.
\item In this context, any probabilistic reasoning about $\hat{\mu}$ is based on a \emph{classical} notion of probability as the theoretical limit of the ratio of occurrences of an event to the total number of trials (i.e. the relative frequency).
\item It can be argued that this notion of probability is ``objective'' -- it derives from an experiment and reflects mechanisms external to an observer.
\item At the same time it is operational only when repeatability is ensured.
	\begin{itemize}\itemsep1em
	\item A football player is allowed to shoot one penalty but misses. Does it matter that he is the best scorer in his team?
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Subjective probability}
\begin{itemize}\itemsep1em
\item The idea of probability is often used in contexts where the classical interpretation as the limit of the relative frequency is not applicable.
\item Consider a person making the following statement: 
\begin{quote}
The probability that there is life on Mars is 1/1000000.
\end{quote}
\item What is this person trying to say?
	\begin{itemize}\itemsep1em
	\item If we could repeatedly try to find life on Mars, this would occur on average once in a million attempts?
	\item If we could recreate the universe over and over, the planet Mars would materialize and there would be life on it once in a million runs?
	\end{itemize}
\item \alert{The term ``probability'' in this context is used as a measure of the \emph{subjective} degree of certainty in the correctness of a statement.}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Subjective probability}
\begin{itemize}\itemsep0.7em
\item ``Probability'' in the above sense can be interpreted as a way to define a fair bet.
\item Take the statement \begin{quote}
The probability that team A will win the game against team B is 2/5.
\end{quote}
\item This can be construed to mean that the person making the statement considers it fair if he has to pay 2 dollars to enter a bet paying back 5 dollars if team A wins.
\item The is related to the concept of \emph{odds}. If the probability of an event is  $\frac{m}{m+n}$, then the associated odds would be $m:n$ ($m$ to $n$).
\item Thus, I'm willing to bet $ m $ dollars to get a profit of $ n $ dollars (recover the initial $ m $ and get additional $ n $ dollars) and I think neither side of the bet is getting an unfair advantage.
\item Clearly, subjective assessments of probability can differ in this context.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Axiomatic foundations of subjective probability}
\begin{itemize}\itemsep0.7em
\item The above considerations may seem informal but they turn out to be consistent with a formal definition of probability.
\item Given a measurable space $(\Omega,\mathcal{F})$ and a relation $\preceq$ over the elements of the $\sigma$-algebra $\mathcal{F}$ having particular properties, it can be shown that the relation $\preceq$ induces a probability measure $P$ on the space $(\Omega,\mathcal{F})$.
\item The ``particular properties'' are basically a formal way of expressing the idea that one event is ``more likely'' or ``more plausible'' than another.
\item The relation is called \emph{relative likelihood}.
\item The corresponding probability measure is known as \emph{subjective probability}.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Two interpretations of probability}
\begin{itemize}\itemsep1em
\item To summarise, the notion of probability can be used in (at least) two contexts:
	\begin{itemize}\itemsep1em
	\item To measure how likely a particular outcome of an ``experiment'' is. This encompasses all sorts of situations whose outcomes can be considered objective: coin tosses, recording data with some degree of imprecision (measurement error) etc.
	\item To measure the personal degree of certainty or conviction about something. This is by definition subjective and assessments about one and the same event can (will!) differ between different people. 
	\end{itemize}
\item With some simplification, objective probability can be thought of as applicable to the modelling of data generation processes with a stochastic element, while subjective probability is applicable to situations where we need to quantify our personal certainty (or ignorance) about something.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Subjective probability in a statistical context}
\begin{itemize}\itemsep1em
\item As a consequence of the above, a probability distribution can be used to measure our degree of uncertainty about the precise value of a numerical variable.
\item This is applicable to unknown parameters that are to be estimated from data.
\item In our example of estimating the mean $ \mu $ of the normally distributed random variable, taking a subjective probability point of view, it would be perfectly acceptable to treat $ \mu $ as a random variable with certain properties.
\item This would merely be a way to formalize our degree of knowledge about $ \mu $ and is therefore applicable even in situations when we know that $ \mu $ is in fact a (unknown) constant.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The Bayesian approach}
\begin{itemize}\itemsep1em
\item Since both the objective and the subjective notions of probability ultimately lead to the same mathematical object, we can also combine them, provided that this combination has a meaningful interpretation. \pause
\item We can treat the available data as generated by an appropriate stochastic mechanism.
\item We can also treat model parameters as random if we agree to work with a subjectivist interpretation of probability.
\item This allows us to combine the sample $\mathbf{x}=(x_1,\ldots,x_n)$ and the parameters in a joint probability distribution (or density, in appropriate contexts).
\item In our example, the joint density would involve $\mathbf{x}$ and
$\mu$: $f(\mathbf{x},\mu)$. (It would also depend on $ \sigma^2 $ but we omit that for simplicity.)
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The Bayesian approach}
\begin{itemize}\itemsep1em
\item This approach allows us to formalize parameter uncertainty but cannot magically help with getting more data or re-running the data generation process.
\item Since in many practical situations the sample $\mathbf{x}$ is fixed and getting more data is difficult or impossible, the object of interest is actually the conditional density of the parameter(s) given available data, i.e. $f(\mu|\mathbf{x})$.
\item The density $f(\mu|\mathbf{x})$ can be obtained by means of Bayes' formula for probability density functions, hence the term Bayesian approach:
\begin{equation}
\label{eq:Bayesformula}
f(\mu|\mathbf{x})=\frac{f(\mathbf{x},\mu)}{f(\mathbf{x})}=\frac{f(\mathbf{x}|\mu)f(\mu)}{f(\mathbf{x})}.
\end{equation}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The Bayesian approach}
\begin{itemize}\itemsep1em
\item The density $ f(\mathbf{x}|\mu) $ is the \emph{likelihood} function for the model. It reflects the data generation mechanism and thus captures the ``objective'' component of the density $f(\mu|\mathbf{x})$.
\item The density $ f(\mu) $ is called the \emph{prior} density. It is formed on the basis of information outside the model (prior to observing the data) and can incorporate a variety of factors like:
	\begin{itemize}\itemsep1em
	\item theoretical considerations
	\item results from previous studies and experiments
	\item subjective judgement on what is reasonable
	\item the modeller's uncertainty about the parameters
	\end{itemize}
\item While the prior corresponds to the ``subjective'' component of the density $f(\mu|\mathbf{x})$, the above factors show that it need not be \emph{ad hoc} or arbitrary but can rigorously incorporate additionally available information.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The Bayesian approach}
\begin{itemize}\itemsep1em
\item The density $f(\mu|\mathbf{x})$ is called the \emph{posterior} density. It combines information coming from the data via the likelihood with additional information coming from the prior.
\item For a given sample the last component of formula \eqref{eq:Bayesformula} -- the density $f(\mathbf{x})$ -- is a constant and does not affect the computations substantively but acts only as a scaling factor. For that reason, formula \eqref{eq:Bayesformula} is often written as
\begin{equation}
\label{eq:BayesProportional}f(\mu|\mathbf{x})\propto
f(\mathbf{x}|\mu)f(\mu),
\end{equation}where $\propto$ denotes proportionality.
\item Sometimes the expression on the right-hand side of $ \propto $ in \eqref{eq:BayesProportional} is called the \emph{kernel} of the posterior density.
\item The above construction obviously does not depend on the dimension of $ \mu $ and will remain valid in a multidimensional setting.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Interpretations of Bayes' formula}
\framesubtitle{}
\begin{itemize}\itemsep1em
\item We can interpret \eqref{eq:BayesProportional} as a mechanism to update an initial body of information in light of new empirical evidence (data).
\item Alternatively, \eqref{eq:BayesProportional} can be interpreted as a mechanism to inform empirical analysis by introducing already available information.
\item In any case this presents the issue of how information is encoded in a prior distribution.
\item At a minimum, this is done by choosing a distribution with appropriate support and calibrating its parameters to ensure, for example, a specific mean and variance.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Some advantages and limitations of the Bayesian approach}
\framesubtitle{}
\begin{itemize}\itemsep1em
\item Bayesian methods can alleviate small-sample problems where the data do not contain enough information to use a classical approach.
\item Bayesian methods can be used to impose theoretically motivated constraints on model parameters.
\item There is the risk that a strong prior will predetermine the outcome of an analysis. This means we can essentially force any result we want.
\item Bayesian methods can be computationally demanding.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{How does it work?}
\framesubtitle{Revisiting the $ \mu $ estimation example in a Bayesian framework}
Let's go back to the example of estimating $ \mu $ from a sample of iid observations from a $N(\mu,\sigma^2)$ random variable with $ \sigma^2 $ known. \bigskip

The likelihood \eqref{eq:NormLik} contains the expression
\begin{equation}
\label{eq:NormLik1}
\begin{split} \sum_{i=1}^{n}(x_i-\mu)^2= &
\sum_{i=1}^{n}\left((x_i-\hat{\mu})-(\mu-\hat{\mu})\right)^2\\
=&\sum_{i=1}^{n}(x_i-\hat{\mu})^2-\sum_{i=1}^{n}2(x_i-\hat{\mu})(\mu-\hat{\mu})+n(\mu-\hat{\mu})^2\\=&\sum_{i=1}^{n}(x_i-\hat{\mu})^2-2(\mu-\hat{\mu})\underbrace{\sum_{i=1}^{n}(x_i-\hat{\mu})}_{0}+n(\mu-\hat{\mu})^2\\
=&\sum_{i=1}^{n}(x_i-\hat{\mu})^2+n(\mu-\hat{\mu})^2 = \nu s^2+n(\mu-\hat{\mu})^2,
\end{split}
\end{equation}
where $\nu=n-1$ and $s^2=\nu^{-1}\sum_{i=1}^{n}(x_i-\hat{\mu})^2$.
\end{frame}

\begin{frame}[fragile]
\frametitle{How does it work?}
\framesubtitle{Revisiting the $ \mu $ estimation example in a Bayesian framework}
Therefore, the likelihood \eqref{eq:NormLik} can be written as
\begin{equation}
\label{eq:NormLik2}
L(\mu,\sigma^2|x_1,\ldots,x_n)=\left( \frac{1}{2\pi\sigma^2}
\right)^{n/2}\exp\left(-\frac{1}{2\sigma^2}\left(\nu
s^2+n(\mu-\hat{\mu})^2\right)\right).
\end{equation} \bigskip

Suppose our prior information on $\mu$ can be summarised by the density
\begin{equation}
\label{eq:NormPrior}
f(\mu)=\frac{1}{\sqrt{2\pi}\sigma^2_a}\exp\left(
-\frac{1}{2\sigma^2_a}(\mu-\mu_a)^2 \right),
\end{equation}
where $\mu_a$ is the prior mean and $\sigma_a^2$ is the prior variance of the person conducting the analysis.
\end{frame}

\begin{frame}[fragile]
\frametitle{How does it work?}
\framesubtitle{Revisiting the $ \mu $ estimation example in a Bayesian framework}
Combining \eqref{eq:NormLik2} and
\eqref{eq:NormPrior} by means of \eqref{eq:BayesProportional},
we obtain \begin{equation}
\label{NormPosterior} \begin{split}
f(\mu|\mathbf{x})\propto & \exp\left( -\frac{1}{2}\left[
\frac{(\mu-\mu_a)^2}{\sigma_a^2}+\frac{n}{\sigma^2}(\mu-\hat{\mu})^2
\right] \right) \\ \propto & \exp \left( -\left(
\frac{\sigma_a^2+\sigma^2/n}{2\sigma^2_a\sigma^2/n} \right)\left(
\mu-\frac{\hat{\mu}\sigma^2_a+\mu_a\frac{\sigma^2}{n}}{\sigma^2_a+\sigma^2/n}
\right)^2 \right). \end{split}
\end{equation}\bigskip

Thus, the posterior distribution of $\mu$ is normal with mean
$$\mathbb{E}[\mu]=\frac{\hat{\mu}\sigma^2_a+\mu_a\sigma^2/n}{\sigma^2_a+\sigma^2/n}=\frac{\hat{\mu}(\sigma^2/n)^{-1}+\mu_a(\sigma_a^2)^{-1}}{(\sigma^2/n)^{-1}+(\sigma^2_a)^{-1}}$$
and variance
$$\mathbb{D}[\mu]=\frac{\sigma^2_a\sigma^2/n}{\sigma^2_a+\sigma^2/n}=\frac{1}{(\sigma^2/n)^{-1}+(\sigma^2_a)^{-1}}.$$
\end{frame}

\begin{frame}[fragile]
\frametitle{How does it work?}
\framesubtitle{Revisiting the $ \mu $ estimation example in a Bayesian framework}
The preceding result can be clarified if we introduce the notation $h_0=(\sigma^2/n)^{-1}$ and $h_a=(\sigma^2_a)^{-1}$. These are called \emph{precision parameters}. \bigskip

Then, we can equivalently write 
\[ \mathbb{E}[\mu]=\dfrac{h_0\hat{\mu}+h_a\mu_a}{h_0+h_a}, \]  \[ \mathbb{D}[\mu]=\frac{1}{h_0+h_a}. \]\bigskip

In other words, the posterior mean turns out to be a weighted average of the sample mean and the prior mean.
\end{frame}
\end{section}


\begin{section}{Extending the Bayesian approach}\label{sec:BayesExt}

\begin{frame}[fragile]
\frametitle{Bayesian updating with new data}
\begin{itemize}\itemsep1em
\item We can use Bayes' theorem to update our information sequentially as new data arrive.
\item Let the initial sample be $\mathbf{x_1}$ and the prior density be $f(\mu)$, leading to a posterior $f(\mu|\mathbf{x_1}) \propto
f(\mu)f(\mathbf{x_1}|\mu)$.
\item Suppose we obtain an additional sample $\mathbf{x_2}$.
\item Then the posterior $f(\mu|\mathbf{x_1})$ can be treated as a prior with respect to the new sample and, using Bayes' theorem, we get
\begin{equation}
\label{eq:Bayesupdate1} f(\mu|\mathbf{x_1},\mathbf{x_2}) \propto
f(\mu|\mathbf{x_1})f(\mathbf{x_2}|\mu),
\end{equation} 
where $f(\mu|\mathbf{x_1},\mathbf{x_2})$ is the posterior obtained with the two samples merged.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Bayesian updating with new data}
\begin{itemize}\itemsep1em
\item Formula \eqref{eq:Bayesupdate1} can also be written as 
\begin{equation}
\label{eq:Bayesupdate2} f(\mu|\mathbf{x_1},\mathbf{x_2}) \propto
f(\mu)f(\mathbf{x_1}|\mu)f(\mathbf{x_2}|\mu).
\end{equation}
\item Since the likelihood function for the merged samples $\mathbf{x_1}$ and $\mathbf{x_2}$ is $f(\mathbf{x_1}|\mu)f(\mathbf{x_2}|\mu)$, the new posterior will be the same regardless of whether we obtain the samples sequentially or we have the full sample $(\mathbf{x_1},\mathbf{x_2})$ from the start.
\item Clearly, this approach generalizes to the case of more than one sample.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Marginal and conditional posterior densities}
\begin{itemize}\itemsep1em
\item As noted, the Bayesian approach works the same way when we are interested in a vector of parameters $\boldsymbol{\theta}$. In this context we denote the joint posterior density by $f(\boldsymbol{\theta}|\mathbf{x})$.
\item In some cases we are interested only in a subset of the parameters $\boldsymbol{\theta}$, i.e. given $\boldsymbol{\theta}=\left(\boldsymbol{\theta_1},\boldsymbol{\theta_2}\right)'$, we would like to separate out the posterior information for $\boldsymbol{\theta_1}$ only.
\item In other words, we are interested in the marginal posterior density of the vector $\boldsymbol{\theta_1}$.
\item It can be obtained as \begin{equation}
\label{eq:MargPost}f(\boldsymbol{\theta_1}|\mathbf{x}) = \int_{R_{\boldsymbol{\theta_2}}}f(\boldsymbol{\theta_1},\boldsymbol{\theta_2}|\mathbf{x})\,d\boldsymbol{\theta_2} = \int_{R_{\boldsymbol{\theta_2}}}f(\boldsymbol{\theta_1}|\boldsymbol{\theta_2},\mathbf{x})f(\boldsymbol{\theta_2|\mathbf{x}})\,d\boldsymbol{\theta_2},
\end{equation}
where $R_{\boldsymbol{\theta_2}}$ is the domain of $\boldsymbol{\theta_2}$ and $f(\boldsymbol{\theta_1}|\boldsymbol{\theta_2},\mathbf{x})$
is the conditional posterior density of $\boldsymbol{\theta_1}$ for given
$\boldsymbol{\theta_2}$ and $\mathbf{x}$.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Marginal and conditional posterior densities}
\begin{itemize}\itemsep1em
\item The expression following the second equality sign in \eqref{eq:MargPost}, \[ \int_{R_{\boldsymbol{\theta_2}}}f(\boldsymbol{\theta_1}|\boldsymbol{\theta_2},\mathbf{x})f(\boldsymbol{\theta_2|\mathbf{x}})\,d\boldsymbol{\theta_2}, \] shows that the marginal posterior density $f(\boldsymbol{\theta_1}|\mathbf{x})$ can be interpreted as the result of averaging the conditional posterior density $f(\boldsymbol{\theta_1}|\boldsymbol{\theta_2},\mathbf{x})$ by using the marginal posterior density $f(\boldsymbol{\theta_2}|\mathbf{x})$ as the weight function.
\item The integration operation in \eqref{eq:MargPost} serves to eliminate the information on the parameters we are \textbf{not} interested in, leaving only the posterior information on the relevant parameters.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Point estimates in a Bayesian framework}
\begin{itemize}\itemsep1em
\item The posterior summarises all the available information (sample and non-sample) about the parameters of interest.
\item The downside is that the posterior is ultimately a probability distribution, while we may need simpler characterizations of the parameters.
\item One example is a situation where we want to produce specific numerical values for the unknown parameters, i.e. we want \emph{point estimates}.
\item Once we have the posterior for the parameter vector $\boldsymbol{\theta}$, the Bayesian way using it to produce a point estimate $\boldsymbol{\hat{\theta}}=\boldsymbol{\hat{\theta}}(\mathbf{x})$ is in a decision-theoretic framework.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Point estimates in a Bayesian framework}
\begin{itemize}\itemsep1em
\item Decision theory requires us to have \emph{loss function} $L(\boldsymbol{\theta},\boldsymbol{\hat{\theta}})$ that measures how ``harmful'' deviations of the estimates $\boldsymbol{\hat{\theta}}$ from the true value $\boldsymbol{\theta}$. 
\item Since in our case $\boldsymbol{\theta}$ is a random variable, the loss function $L(\boldsymbol{\theta},\boldsymbol{\hat{\theta}})$ will also be random, even though the sample $\mathbf{x}$ is fixed.
\item Thus, we need to work with the expected loss function.
\item Since the posterior summarizes the information on $\boldsymbol{\theta}$, it is natural to construct the expectation with respect to $ f(\boldsymbol{\theta}|\mathbf{x}) $.
\item We are then in a position to compute the expected loss associated with an estimate $\boldsymbol{\hat{\theta}}$.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Point estimates in a Bayesian framework}
\begin{itemize}\itemsep1em
\item Then, the optimal point estimate would be the one that minimizes the expectation of the loss function: \begin{equation}
\label{ExpLoss}
\boldsymbol{\hat{\theta^*}}=\min_{\boldsymbol{\hat{\theta}}}\mathbb{E}[L(\boldsymbol{\theta},\boldsymbol{\hat{\theta}})]=\min_{\boldsymbol{\hat{\theta}}}\int_{R_{\boldsymbol{\theta}}}
L(\boldsymbol{\theta},\boldsymbol{\hat{\theta}})f(\boldsymbol{\theta}|\mathbf{x})
d\boldsymbol{\theta}.
\end{equation} 
\item The expected loss function is called \emph{risk} or \emph{risk function}.
\item We are implicitly assuming that both the expectation and the minimum exist.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Point estimates in a Bayesian framework}
\begin{itemize}\itemsep1em
\item As an example, take the quadratic loss function $L(\boldsymbol{\theta},\boldsymbol{\hat{\theta}})=(\boldsymbol{\theta}-\boldsymbol{\hat{\theta}})'C(\boldsymbol{\theta}-\boldsymbol{\hat{\theta}})$,
where $C$ is a fixed symmetric positive definite matrix.
\item Then the posterior expectation of $L(\boldsymbol{\theta},\boldsymbol{\hat{\theta}})$ is 
\begin{equation}
\label{eq:QuadExpLoss}\begin{split}
\mathbb{E}[L(\boldsymbol{\theta},\boldsymbol{\hat{\theta}})]=&\mathbb{E}[(\boldsymbol{\theta}-\boldsymbol{\hat{\theta}})'C(\boldsymbol{\theta}-\boldsymbol{\hat{\theta}})]\\=&\mathbb{E}[((\boldsymbol{\theta}-\mathbb{E}[\boldsymbol{\theta}])-(\boldsymbol{\hat{\theta}}-\mathbb{E}[\boldsymbol{\theta}]))'C((\boldsymbol{\theta}-\mathbb{E}[\boldsymbol{\theta}])-(\boldsymbol{\hat{\theta}}-\mathbb{E}[\boldsymbol{\theta}]))]\\=&\mathbb{E}[(\boldsymbol{\theta}-\mathbb{E}[\boldsymbol{\theta}])'C(\boldsymbol{\theta}-\mathbb{E}[\boldsymbol{\theta}])]+(\boldsymbol{\hat{\theta}}-\mathbb{E}[\boldsymbol{\theta}])'C(\boldsymbol{\hat{\theta}}-\mathbb{E}[\boldsymbol{\theta}]),
\end{split}
\end{equation}
where the second term in the last equality is not stochastic and can be taken out of the expectation. (Note that in going from the second to the third line terms of the form $ \mathbb{E}[(\boldsymbol{\theta}-\mathbb{E}[\boldsymbol{\theta}])'C (\boldsymbol{\hat{\theta}}-\mathbb{E}[\boldsymbol{\theta}])] $ will disappear since $ \mathbb{E}[\boldsymbol{\theta}-\mathbb{E}[\boldsymbol{\theta}]] = \mathbf{0}  $.)
\item At the same time, it is precisely the last term of  \eqref{eq:QuadExpLoss} that depends on $\boldsymbol{\hat{\theta}}$ and determines the minimum.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Point estimates in a Bayesian framework}
\begin{itemize}\itemsep1em
\item Clearly for a positive definite $ C $ the minimum is attained at $\boldsymbol{\hat{\theta^*}}=\mathbb{E}[\boldsymbol{\theta}]$.
\item Thus, for the quadratic loss function the optimal point estimate is given by the mean\footnote{Assuming it exists in the first place.} of the respective posterior distribution.\bigskip \pause
\item As further examples, for a univariate parameter $ \theta $ and an absolute deviation loss function $L(\theta,\hat{\theta})=|\theta-\hat{\theta}|$ (plus technical assumptions), the optimal point estimate can be shown to be the median.
\item A zero-one loss function of the form \begin{equation*} L(\boldsymbol{\theta},\boldsymbol{\hat{\theta}})=\left\{ \begin{aligned} &0,~\boldsymbol{\hat{\theta}}=\boldsymbol{\theta}\\ &1,~\boldsymbol{\hat{\theta}}\neq\boldsymbol{\theta} \end{aligned}\right.
,\end{equation*} will yield a mode of the posterior as the optimal point estimate (again under technical assumptions).
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Bayesian credible regions}
\framesubtitle{}
\begin{itemize}\itemsep1em
\item The Bayesian counterpart of a confidence interval is called a \emph{credible region}.
\item If we have the posterior density $f(\boldsymbol{\theta}|\mathbf{x})$, we can compute the probability that the vector of parameters $\boldsymbol{\theta}$ belongs to a given subset $\bar{R}$ of the space of parameters:
\begin{equation}
\label{eq:CredReg} P(\boldsymbol{\theta}\in
\bar{R}|\mathbf{x}) = \int_{\bar{R}}f(\boldsymbol{\theta} | \mathbf{x}) \, d\boldsymbol{\theta}.
\end{equation}\pause
\item We can also approach the problem from the opposite direction: for a fixed probability $P(\boldsymbol{\theta}\in \bar{R}|\mathbf{x})$, find a region $\bar{R}$ such that \eqref{eq:CredReg} holds.
\item In general such a region will not be unique.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Bayesian credible regions}
\begin{itemize}\itemsep1em
\item If the posterior is unimodal, in some cases a unique credible region can be obtained by imposing an additional requirement known as \emph{highest posterior density}.
\item This requirement is intuitively described along the lines ``the posterior density values over that region should not be smaller than those for any other region with the same probability''...
\item ...but a more precise characterization would be related to the fact that they minimize the volume enclosed in the parameter space among all regions with the same probability.
\item For example, a unimodal symmetric density in the case of one parameter would produce a credible region that is an interval centred on the mode and containing the largest values of the posterior density (or, equivalently, being the smallest in length).
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Bayesian credible regions}
\begin{itemize}\itemsep1em
\item It should be remembered that, despite the superficial similarity, Bayesian credible regions are conceptually different from classical confidence intervals.
\item A classical confidence interval is considered random and probabilistic statements relate to the probability that this random interval will cover the fixed (but unknown) value of the parameter of interest.
\item In contrast, a Bayesian credible region is considered deterministic and probabilistic statements relate to the probability with which the random parameter of interest will fall in that pre-specified region.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Marginal distribution of the observations}
\framesubtitle{}
\begin{itemize}\itemsep1em
\item Sometimes we are interested in the marginal density of the observations $f(\mathbf{x})$.
\item These can be derived as follows:
\begin{equation}
\label{eq:MargObs}f(\mathbf{x})=\int_{R_{\boldsymbol{\theta}}}f(\boldsymbol{\theta},\mathbf{x})d\boldsymbol{\theta}=\int_{R_{\boldsymbol{\theta}}}f(\mathbf{x}|\boldsymbol{\theta})f(\boldsymbol{\theta})d\boldsymbol{\theta}.
\end{equation}
\item The expression after the second equality sign in \eqref{eq:MargObs} means that the marginal density can be viewed as averaging the likelihood function by using the prior density as a weighting function.
\end{itemize}
\end{frame}











\end{section}

\begin{section}{The linear regression model in a Bayesian framework}\label{sec:BayesLM}

\end{section}


\begin{frame}[fragile]
\frametitle{Readings}
Readings:\bigskip

William H. Greene. \emph{Econometric Analysis}, $ 7^{\text{th}} $ edition. Chapter 16.\bigskip

Additional readings:\bigskip

Gary Koop. \emph{Bayesian Econometrics}. 2003. Wiley.
\end{frame}

\end{document}



\subsection{Прогнозни плътности на разпределения}

При разглеждането на задачи за прогнозиране в бейсов контекст един
от важните въпроси е какво е разпределението на още ненаблюдавани
събития $\mathbf{\tilde{x}}$. Разглеждаме съвместната плътност на
нерегистрираните данни $\mathbf{\tilde{x}}$ и параметрите
$\boldsymbol{\theta}$ при условие вече наблюдаваните данни $\mathbf{x}$:
\beq \label{JntData}
f(\mathbf{\tilde{x}},\boldsymbol{\theta}|\mathbf{x})=f(\mathbf{\tilde{x}}|\boldsymbol{\theta},\mathbf{x})f(\boldsymbol{\theta}|\mathbf{x}).
\eeq Тогава прогнозната плътност на $\mathbf{\tilde{x}}$ при
условие $\mathbf{x}$ се получава след интегриране в
\eqref{JntData} по $\boldsymbol{\theta}$: \beq \label{MargForec}
f(\mathbf{\tilde{x}}|\mathbf{x})=\int_{R_{\boldsymbol{\theta}}}f(\mathbf{\tilde{x}},\boldsymbol{\theta}|\mathbf{x})d\boldsymbol{\theta}=\int_{R_{\boldsymbol{\theta}}}f(\mathbf{\tilde{x}}|\boldsymbol{\theta},\mathbf{x})f(\boldsymbol{\theta}|\mathbf{x})d\boldsymbol{\theta}.
\eeq Последният израз в \eqref{MargForec} означава, че прогнозната
плътност може да се интерпретира и като математическото очакване
на условната прогнозна плътност по отношение на апостериорната
плътност.

\subsection{Точкови прогнози}

Получената в предишната секция прогнозна плътност
$f(\mathbf{\tilde{x}}|\mathbf{x})$ може да се използва, за да
бъдат направени точкови прогнози за бъдещи данни. Принципът на
получаване е същият, както за точковите оценки. Ако
$\mathbf{\hat{x}}$ е точковата прогноза за ненаблюдаваните данни
$\mathbf{\tilde{x}}$, то е необходима функция на загубите
$L(\mathbf{\tilde{x}},\mathbf{\hat{x}})$, с помощта на която можем
да запишем функция на риска и да минимизираме последната по
$\mathbf{\hat{x}}$ т.е. \beq \label{PointForec}
\min_{\mathbf{\hat{x}}}\int_{R_{\mathbf{\tilde{x}}}}L(\mathbf{\tilde{x}},\mathbf{\hat{x}})f(\mathbf{\tilde{x}}|\mathbf{x})d\mathbf{\tilde{x}}.
\eeq Тук $R_{\mathbf{\tilde{x}}}$ означава областта на изменение
на $\mathbf{\tilde{x}}$. Решението на \eqref{PointForec}, ако
съществува, се явява оптимална точкова прогноза за
$\mathbf{\tilde{x}}$. И в този случай важат изводите за типа
точкови прогнози, получавани при определен вид функция на
загубите: очакването на $f(\mathbf{\tilde{x}}|\mathbf{x})$ за
квадратична функция на загубите, медианата за абсолютна грешка и
т.н.

\subsection{Прогнозни области}

Ако имаме прогнозната плътност $f(\mathbf{\tilde{x}}|\mathbf{x})$,
бихме могли да изчислим вероятността бъдещите наблюдения
$\mathbf{\tilde{x}}$ да попаднат в дадена подобласт $\bar{R}$ на
областта им на изменение: \beq
\label{CredRegForec}P(\mathbf{\tilde{x}}\in
\bar{R}|\mathbf{x})=\int_{\bar{R}}f(\mathbf{\tilde{x}}|\mathbf{x})d\mathbf{\tilde{x}}.
\eeq Съвсем аналогично на областите на достоверност, разгледани в
секция \ref{BayesRegion}, можем да решаваме и обратната задача,
при която за зададена вероятност $P(\mathbf{\tilde{x}}\in
\bar{R}|\mathbf{x})$ се търси област $\bar{R}$ (\emph{прогнозна
област}), която удовлетворява \eqref{CredRegForec}. И в този
случай единствеността на такава област не е гарантирана изобщо, но
ако прогнозната плътност $f(\mathbf{\tilde{x}}|\mathbf{x})$ е
унимодална и допълнително наложим изискването за област с
,,максимална прогнозна плътност'', можем да получим единствена
прогнозна област.

\subsection{Бейсова проверка на хипотези}

В контекста на бейсовата статистика проверката на хипотези
представлява вероятностно сравняване на \emph{равнопоставени}
алтернативи, поради което понятието за нулева хипотеза няма
особеното значение, което му се придава в класическите
изследвания. В общия случай разглеждаме твърдения $H_0$ и $H_1$,
които се отнасят до различни модели $M_0$ и $M_1$ за данните
$\mathbf{x}$. За модел $M_i,~i=1,2,$ съответната функция на
правдоподобие е $f_i(\mathbf{x}|\boldsymbol{\theta_i})$, а априорната
плътност е $f_i(\boldsymbol{\theta_i})$. Тук долните индекси $i$ в
правдоподобията и априорните плътности са използвани, за да
отчетем възможността да се сравняват хипотези за различни
механизми на генериране на данните, съответно с различни априорни
очаквания. Това не изключва възможността да се разглеждат
по-прости случаи, например когато параметрите $\boldsymbol{\theta_0}$ и
$\boldsymbol{\theta_1}$, в съответствие с хипотези $H_0$ и $H_1$ се
изменят в различни области на едно и също параметрично
пространство.

При условие, че е верен модел $M_i$, маргиналната плътност на
данните (\emph{маргинална функция на правдоподобие}) е \beq
\label{MargLik}
f(\mathbf{x}|M_i)=\int_{R_{\boldsymbol{\theta_i}}}f_i(\mathbf{x}|\boldsymbol{\theta_i})f_i(\boldsymbol{\theta_i})d\boldsymbol{\theta_i}.\eeq

Тогава \emph{множител на Бейс} се дефинира като отношението между
маргиналните функции на правдоподобие за двата модела: \beq
\label{BayesFactor}B_{01}(\mathbf{x})=\frac{f(\mathbf{x}|M_0)}{f(\mathbf{x}|M_1)}.\eeq
Интуитивно множител на Бейс, който е по-голям от 1, може да се
интерпретира като индикация за по-голяма достоверност на модел
$M_0$ (или съответно $H_0$) в сравнение с $M_1$ $(H_1)$.

При анализ в бейсова схема може да има априорна информация и за
достоверността на самите модели, която да се отчете при
сравняването на хипотезите. Ако $P(M_i)$ е априорната вероятност
на модел $M_i$, то можем да изчислим апостериорната вероятност на
на този модел при условие данните $\mathbf{x}$ с помощта на
формулата на Бейс: \beq
\label{ModelPost}P(M_i|\mathbf{x})=\frac{P(M_i)f(\mathbf{x}|M_i)}{\sum_{j=0}^{1}P(M_j)f(\mathbf{x}|M_j)}.
\eeq Тогава \emph{апостериорният шанс} в полза на модел $M_0$
сравнен с $M_1$ се дефинира като отношението на апостериорните
вероятности на двата модела: \beq
\label{PostOdds}K_{01}(\mathbf{x})=\frac{P(M_0|\mathbf{x})}{P(M_1|\mathbf{x})}=\frac{P(M_0)}{P(M_1)}\times
\frac{f(\mathbf{x}|M_0)}{f(\mathbf{x}|M_1)}=\frac{P(M_0)}{P(M_1)}B_{01}(\mathbf{x}).
\eeq Уравнение \eqref{PostOdds} показва защо $B_{01}(\mathbf{x})$
се нарича множител на Бейс: това е величината, с която умножаваме
\emph{априорния шанс} $P(M_0)/P(M_1)$, за да го коригираме с
информацията от данните и да стигнем до апостериорния шанс. С
други думи, множителят на Бейс показва дали наблюдаваните данни
увеличават или намаляват достоверността на единия модел в
сравнение с другия.

Макар че горните разглеждания бяха дадени в термините на
сравняване на модели, те се пренасят без изменения и за случая на
сравняване на хипотези. Това означава, че ако сме изчислили
апостериорния шанс $K_{01}(\mathbf{x})$ при сравняване на хипотеза
$H_0$ с $H_1$, с негова помощ можем да определим коя хипотеза е
по-вероятна. При отсъствието на априорна информация в полза на
едната от двете хипотези, те могат да се разглеждат като
равновероятни и съответно априорният шанс е единица. Тогава
апостериорният шанс става равен на множителя на Бейс и
$B_{01}(\mathbf{x})$ е достатъчен, за да се направи извод за
сравняваните хипотези.

Ако задачата е в явен вид да се приеме или отхвърли хипотезата
$H_0$ в сравнение с $H_1$, използването само на апостериорния
шанс\footnote{Например като се прилагат правила от типа ,,Ако
$K_{01}(\mathbf{x})\geq 1$ приемаме $H_0$, в противен случай
отхвърляме $H_0$.''} е относително непрецизно средство за вземане
на решение. В такива случаи се препоръчва да се работи от гледна
точка на теорията за вземане на решения, като се запише в явен вид
функция на загубите $L(H_i,\hat{H}_j)$, където $H_i$ е истинското
състояние, а $\hat{H}_j$ е приетата от изследователя хипотеза.
След това можем да изчислим очакването на функцията на загубите
при условие, че е взето решение $\hat{H}_j$ и да приемем онова
$\hat{H}_j$, за което съответната очаквана загуба е най-малка.

\subsection{Някои общи бележки върху бейсовите методи}

\subsubsection{Информативни и неинформативни априорни плътности}

Дотук в изложението приемахме, че априорните плътности са избрани
така, че да отразяват наличната неекспериментална информация. В
този смисъл тези плътности могат да бъдат наречени
\emph{информативни}. Можем да си зададем въпроса как да провеждаме
бейсовия анализ в ситуации, за които не разполагаме с
предварителна информация. Интуитивно е да се приеме, че в такива
случаи различните възможни стойности на изследваните параметри са
равновероятни. За съжаление подобна трактовка води до проблеми в
непрекъснатия случай: ако например сме решили да изберем
априорната плътност като плътност на равномерно разпределение в
някакъв интервал, тогава фиксирането на носителя на равномерното
разпределение всъщност представлява вкарване на информация в
анализа, доколкото извън него слагаме вероятност нула на
съответните стойности на параметъра. При това положение понятието
за \emph{неинформативна} плътност става проблематично. Може да се
покаже, че при налагането на определени изисквания за
неинформативност плътностите, които отговарят на тях са
несобствени в смисъл, че те не се интегрират до крайно число.

При положение, че интеграл от неинформативна ,,плътност'' е
разходящ, такъв обект разбира се не се явява плътност на
вероятностно разпределение в истинския смисъл на думата. Въпреки
всичко функции с такива свойства могат да бъдат полезни, ако
апостериорната плътност остава истинска вероятностна плътност или,
с други думи, ако ядрото \'и е с краен интеграл. Тогава бейсовият
анализ може да бъде провеждан и съответно изводите от него ще
бъдат само на база информация, получена от наблюдаваните данни.
Често пъти изводи или оценки, получени при използването на
неинформативни априорни плътности за достатъчно големи извадки
съвпадат с тези, получени от класическия статистически анализ.
Макар че тук няма да разглеждаме бейсов анализ с неинформативни
плътности, заради пълнотата на изложението отбелязваме това важно
направление в бейсовата статистика.

\subsubsection{Монте Карло симулации с марковски вериги}

Ясно е, че при степента на общност на горните резултати изборът на
априорна плътност и на функция на правдоподобие може да води до
най-разнообразни апостериорни плътности. В повечето случаи тези
апостериорни плътности не могат да бъдат изследвани аналитично и
се налага да се прибегне до численото им изследване. За съжаление
в случаите на многомерни параметри обработката на тези плътности
дори с помощта на мощни компютри е затруднена, доколкото
симулирането на случайни извадки от тях или интегрирането им
създават големи изчислителни затруднения при използването на
стандартни числени методи. В миналото този проблем е бил
заобикалян с помощта на т.нар. \emph{спрегнати} априорни
плътности, т.е. априорни плътности, за които получената
апостериорна плътност е от същия клас. Избирани са били спрегнати
плътности, които са достатъчно лесни за аналитично изследване или
числена обработка.

С навлизането на достатъчно мощна изчислителна техника през
последните 20 години бейсовият анализ започва да използва клас от
методи за числено симулиране, известни като \emph{Монте Карло
симулации с марковски вериги (МКСМВ)}\footnote{Английският термин
е \emph{Markov Chain Monte Carlo (MCMC)}.}. Те са силно интензивни
от изчислителна гледна точка, но са особено ефективни за целите на
бейсовия анализ. Основната идея на тези методи е да се симулира
достатъчно голяма извадка от апостериорната плътност като
реализация от подходящо построена марковска верига. След това
анализът на свойствата на апостериорното разпределение се прави на
основата на така генерираната извадка. Обръщаме внимание, че
повечето от бейсовите резултати, които могат да бъдат намерени в
специализираната литература, са получени именно с помощта на
МКСМВ, а не аналитично.

\section{Бейсов иконометричен анализ на линейния регресионен модел}

За целите на анализа разглеждаме познатия ни линеен регресионен
модел \beq \label{LinRegMod}
\mathbf{y}=X\boldsymbol{\beta}+\mathbf{e},\eeq където разполагаме с $T$
наблюдения и имаме $K$ параметъра. За матрицата $X$ предполагаме,
че е нестохастична\footnote{В случая разсъжденията са аналогични и
за стохастична $X$ при положение, че тя е независима от грешката
$\mathbf{e}$.} и е изпълнено $rank(X)=K$, а за грешката
$\mathbf{e}\in N(\mathbf{0},\sigma^2 I_T)$.

Функцията на правдоподобие за \eqref{LinRegMod} при допускането за
нормалност на грешката е \beq \label{LRMLik} \ell
(\mathbf{y}|\boldsymbol{\beta}, \sigma^2)=(2\pi \sigma^2)^{-T/2}\exp
\left[
-\frac{(\mathbf{y}-X\boldsymbol{\beta})'(\mathbf{y}-X\boldsymbol{\beta})}{2\sigma^2}
\right]. \eeq Съгласно принципите на бейсовия анализ параметрите
на модела $\boldsymbol{\beta}$ и $\sigma^2$ се разглеждат като случайни и
съответно за тях трябва да бъде зададена априорна плътност. За
случая избираме следната априорна плътност (представена само с
ядрото си): \beq
\label{LRMPrior}f(\boldsymbol{\beta},\sigma)\propto\sigma^{-m}\exp\left[
-\frac{1}{2\sigma^2}[\eta+(\boldsymbol{\beta}-\boldsymbol{\mu})'\boldsymbol{\Psi}^{-1}(\boldsymbol{\beta}-\boldsymbol{\mu})]
\right], \eeq където $m>K+1$, $\eta>0$ и $\boldsymbol{\Psi}$ е симетрична
и положително определена. Тази априорна плътност е пример за
спрегната плътност за съответната функция на правдоподобие.
Изборът на \eqref{LRMPrior} за априорна плътност може да бъде
изяснен по-добре, ако разложим $f(\boldsymbol{\beta},\sigma)$ като \beq
\label{DecompLMRPrior}
f(\boldsymbol{\beta},\sigma)=f(\boldsymbol{\beta}|\sigma)f(\sigma), \eeq където
\beq
\label{CondBeta}f(\boldsymbol{\beta}|\sigma)=\frac{1}{(2\pi)^{K/2}\sigma^K
[\det (\boldsymbol{\Psi})]^{1/2}}\exp \left[
-\frac{1}{2\sigma^2}(\boldsymbol{\beta}-\boldsymbol{\mu})'\boldsymbol{\Psi}^{-1}(\boldsymbol{\beta}-\boldsymbol{\mu})\right]\eeq
и \beq \label{SigmaPrior}f(\sigma)\propto \sigma^{-(m-K)}\exp
\left[ -\frac{\eta}{2\sigma^2} \right],\quad \sigma>0. \eeq Тоест
условно по $\sigma$ векторът $\boldsymbol{\beta}$ е многомерно нормално
разпределен със средна $\boldsymbol{\mu}$ и ковариационна матрица
$\sigma^2\boldsymbol{\Psi}$. Разпределението на $\sigma$, съответстващо на
ядрото \eqref{SigmaPrior}, може да се получи като нелинейна
трансформация на гама-разпределена случайна величина.

При използването на априорната плътност \eqref{LRMPrior} и
функцията на правдоподобие \eqref{LRMLik} за апостериорното
разпределение на разглеждания модел се получава следното ядро:
\beq
\label{LRMPost}\begin{split}f(\boldsymbol{\beta},\sigma|\mathbf{y})\propto
& \frac{1}{\sigma^{T+m}}\exp\left[
-\frac{1}{2\sigma^2}\left[(T-K)\hat{\sigma}^2+(\boldsymbol{\beta}-\mathbf{b})'X'X(\boldsymbol{\beta}-\mathbf{b})\right]
\right]\\& \times \exp \left[
-\frac{1}{2\sigma^2}\left[\eta+(\boldsymbol{\beta}-\boldsymbol{\mu})'\boldsymbol{\Psi}^{-1}(\boldsymbol{\beta}-\boldsymbol{\mu})\right]
\right], \end{split}\eeq където $\hat{\sigma}^2=RSS/(T-K)$ и
$\mathbf{b}$ са оценките по МНМК за дисперсията и вектора на
коефициентите. Алгебрично еквивалентен запис за ядрото в
\eqref{LRMPost} е \beq
\label{LRMPost1}f(\boldsymbol{\beta},\sigma|\mathbf{y})\propto\frac{1}{\sigma^{T+m}}\exp
\left[
-\frac{1}{2\sigma^2}[(\boldsymbol{\beta}-\boldsymbol{\beta_*})'(\boldsymbol{\Psi}^{-1}+X'X)(\boldsymbol{\beta}-\boldsymbol{\beta_*})+\xi]
\right], \eeq където
$$\boldsymbol{\beta_*}=(\boldsymbol{\Psi}^{-1}+X'X)^{-1}(\boldsymbol{\Psi}^{-1}\boldsymbol{\mu}+X'X\mathbf{b})$$
и
$$\xi=\eta+(T-K)\hat{\sigma}^2+\boldsymbol{\mu}'\boldsymbol{\Psi}^{-1}\boldsymbol{\mu}+\mathbf{b}'X'X\mathbf{b}-\boldsymbol{\beta_*}'(\boldsymbol{\Psi}^{-1}+X'X)\boldsymbol{\beta_*}.$$

Маргиналното апостериорно разпределение за $\boldsymbol{\beta}$ може да
бъде получено стандартно, като \eqref{LRMPost1} се интегрира по
$\sigma$. Неговото ядро има вида \beq
\label{MargPostBeta}\begin{split} f(\boldsymbol{\beta}|\mathbf{y})\propto
& \left[ \xi +
(\boldsymbol{\beta}-\boldsymbol{\beta_*})'(\boldsymbol{\Psi}^{-1}+X'X)(\boldsymbol{\beta}-\boldsymbol{\beta_*})
\right]^{-(T+m-1)/2}\\ \propto & \left[
v+(\boldsymbol{\beta}-\boldsymbol{\beta_*})'\frac{v}{\xi}(\boldsymbol{\Psi}^{-1}+X'X)(\boldsymbol{\beta}-\boldsymbol{\beta_*})\right]^{-(v+K)/2},
\end{split}\eeq където $v=T+m-K-1$. Полученото ядро е от плътност
на многомерно $t$-разпределение. Случаен вектор с такова
разпределение ще има очакване $\boldsymbol{\beta_*}$ за $T+m-K>2$ и
ковариационна матрица $$\left( \frac{\xi}{T+m-K-3}
\right)(\boldsymbol{\Psi}^{-1}+X'X)^{-1} \textrm{ за } T+m-K>3.$$ Ако сме
означили $\mathbf{h}=\left[ \frac{v}{\xi}(\boldsymbol{\Psi}^{-1}+X'X)
\right]$, то разпределението на $j$-тия компонент на $\boldsymbol{\beta}$,
$\beta_j$, може да се получи като се отчете, че
$(\beta_j-\beta_{*j})/[h^{-1}(j,j)]^{1/2}$ има едномерно
$t$-разпределение с $v$ степени на свобода. Тук означението в
знаменателя е използвано за корен квадратен от $j$-тия диагонален
елемент на матрицата $\mathbf{h}^{-1}$.

Може да се покаже, че многомерното $t$-разпределение е затворен
клас по отношение на линейни трансформации (с точност до смяна на
параметрите на разпределението). Също така анализът на
разглеждания модел може да стъпи на това, че \beq
\label{QuadBeta}\frac{T+m-K-1}{K\xi}(\mathbf{B}-\boldsymbol{\beta_*})'(\boldsymbol{\Psi}^{-1}+X'X)(\mathbf{B}-\boldsymbol{\beta_*})\eeq
е разпределена като $F(K,v)$ случайна величина, където с
$\mathbf{B}$ сме означили случаен вектор с ядро на плътността
\eqref{MargPostBeta}. Аналогично, ако $C$ е матрица с размерност
$J\times K$, то \beq \label{TransfQuadBeta}
\frac{T+m-K-1}{J\xi}[C(\mathbf{B}-\boldsymbol{\beta_*})]'[C(\boldsymbol{\Psi}^{-1}+X'X)^{-1}C']^{-1}[C(\mathbf{B}-\boldsymbol{\beta_*})]
\eeq има $F(J,v)$ разпределение. С помощта на тези резултати могат
да се правят изследвания на свойствата на $\boldsymbol{\beta}$,
включително да се строят бейсови области и да се проверяват
хипотези.